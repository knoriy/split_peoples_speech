{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import textgrids\n",
    "import pandas as pd\n",
    "\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import shutil\n",
    "import fsspec\n",
    "from utils import generate_txt, get_subset_df, genorate_pps_df, make_tarfile\n",
    "\n",
    "chunk = 10\n",
    "generate_subset_tsv = True\n",
    "pps_df_dir = '/home/knoriy/split_peoples_speech/pps_train.tsv'\n",
    "\n",
    "root_path = '/home/knoriy/split_peoples_speech/'\n",
    "dataset_name = 'pps_train'\n",
    "\n",
    "metadata_dir = \"/mnt/knoriy/metadata.json\"\n",
    "tar_dir = \"/mnt/knoriy/pps_train.tar\"\n",
    "\n",
    "# init Dirs\n",
    "dataset_root_path = os.path.join(root_path, f'{dataset_name}')\n",
    "dataset_textgrid_path = os.path.join(root_path, f'{dataset_name}_textgrids')\n",
    "dataset_split_path = os.path.join(root_path, f'{dataset_name}_split')\n",
    "\n",
    "s3_dest = fsspec.filesystem('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(pps_df_dir):\n",
    "    pps_df = pd.read_csv(pps_df_dir, sep='\\t', header=None, names=['audio_filepath', 'text'])\n",
    "else:\n",
    "    pps_df = genorate_pps_df(metadata_dir)\n",
    "    pps_df.to_csv(pps_df_dir, sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>is there anything to wear it on this one or ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>i thought the law was that we don't have juris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>review it yes you do yes you do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>this you know what happened there was a single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>motion to abandon the quantity because nothing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320997</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00011.flac</td>\n",
       "      <td>reward of all our marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320998</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00012.flac</td>\n",
       "      <td>so i traveled back the way i'd come on it this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320999</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00013.flac</td>\n",
       "      <td>you state your business mister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321000</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00014.flac</td>\n",
       "      <td>come out yet i don't want to be just that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321001</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00015.flac</td>\n",
       "      <td>we're going to hire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4321002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            audio_filepath  \\\n",
       "0        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "1        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "2        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "3        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "4        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "...                                                    ...   \n",
       "4320997       The_Capture_movie/Capture_DOT_mp3_00011.flac   \n",
       "4320998       The_Capture_movie/Capture_DOT_mp3_00012.flac   \n",
       "4320999       The_Capture_movie/Capture_DOT_mp3_00013.flac   \n",
       "4321000       The_Capture_movie/Capture_DOT_mp3_00014.flac   \n",
       "4321001       The_Capture_movie/Capture_DOT_mp3_00015.flac   \n",
       "\n",
       "                                                      text  \n",
       "0        is there anything to wear it on this one or ha...  \n",
       "1        i thought the law was that we don't have juris...  \n",
       "2                          review it yes you do yes you do  \n",
       "3        this you know what happened there was a single...  \n",
       "4        motion to abandon the quantity because nothing...  \n",
       "...                                                    ...  \n",
       "4320997                         reward of all our marriage  \n",
       "4320998  so i traveled back the way i'd come on it this...  \n",
       "4320999                     you state your business mister  \n",
       "4321000          come out yet i don't want to be just that  \n",
       "4321001                                we're going to hire  \n",
       "\n",
       "[4321002 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file: This may take some time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_file_obj = tarfile.open(tar_dir, mode='r')\n",
    "print('opening file: This may take some time\\n')\n",
    "\n",
    "file_names_full_list = src_file_obj.getnames()\n",
    "file_names_full_list = [i for i in file_names_full_list if '.flac' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files found 4321002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Files: 100%|██████████| 10/10 [00:03<00:00,  2.67it/s]\n",
      "Generating .txt files for MFA: 100%|██████████| 10/10 [00:00<00:00, 2760.68it/s]\n",
      "Converting .flac files to .wav: 100%|██████████| 10/10 [00:01<00:00,  6.76it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/bin/mfa\", line 7, in <module>\n",
      "    from montreal_forced_aligner.command_line.mfa import main\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/__init__.py\", line 4, in <module>\n",
      "    import montreal_forced_aligner.acoustic_modeling as acoustic_modeling\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/acoustic_modeling/__init__.py\", line 7, in <module>\n",
      "    from montreal_forced_aligner.acoustic_modeling.base import AcousticModelTrainingMixin  # noqa\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/acoustic_modeling/base.py\", line 20, in <module>\n",
      "    from montreal_forced_aligner.alignment import AlignMixin\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/alignment/__init__.py\", line 6, in <module>\n",
      "    from montreal_forced_aligner.alignment.adapting import AdaptingAligner\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/alignment/adapting.py\", line 15, in <module>\n",
      "    from montreal_forced_aligner.alignment.multiprocessing import AccStatsArguments, AccStatsFunction\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/alignment/multiprocessing.py\", line 27, in <module>\n",
      "    from montreal_forced_aligner.db import Dictionary, File, Phone, Speaker, Utterance, Word\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/montreal_forced_aligner/db.py\", line 7, in <module>\n",
      "    import librosa\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/librosa/__init__.py\", line 209, in <module>\n",
      "    from . import core\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/librosa/core/__init__.py\", line 6, in <module>\n",
      "    from .audio import *  # pylint: disable=wildcard-import\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/librosa/core/audio.py\", line 8, in <module>\n",
      "    import soundfile as sf\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/soundfile.py\", line 17, in <module>\n",
      "    from _soundfile import ffi as _ffi\n",
      "  File \"/home/knoriy/miniconda3/envs/aligner/lib/python3.10/site-packages/_soundfile.py\", line 2, in <module>\n",
      "    import _cffi_backend\n",
      "ImportError: libffi.so.7: cannot open shared object file: No such file or directory\n",
      "Chunks remaining:   0%|          | 0/432101 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Total Files found', len(file_names_full_list))\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(file_names_full_list), chunk), desc='Chunks remaining: '):\n",
    "    for file_name in tqdm.tqdm(file_names_full_list[i:i + chunk], desc=\"Extracting Files: \"):\n",
    "        src_file_obj.extract(file_name, f'./{dataset_name}/')\n",
    "\n",
    "    if generate_subset_tsv == True:\n",
    "        df = get_subset_df(f'{dataset_root_path}/**/*.flac', pps_df)\n",
    "\n",
    "    # Save transcript to file\n",
    "    save_all_text_to_file(df, dataset_name)\n",
    "\n",
    "    # Convert Flac to wav\n",
    "    convert_all_to_wav(df, os.path.join(root_path, dataset_name))\n",
    "\n",
    "    # Get audio text alignments and split audio\n",
    "    generate_textgrids(os.path.join(root_path, dataset_name))\n",
    "    # split_all_audio_files(dataset_textgrid_path, dataset_root_path)\n",
    "\n",
    "    # Upload Split files to s3\n",
    "    # tar_file_path = make_tarfile(f'{dataset_split_path}', f'{dataset_root_path}/{i}.tar')\n",
    "    # s3_dest.put(tar_file_path, f's-laion/peoples_speech/{dataset_name}_split/')\n",
    "\n",
    "    # shutil.rmtree(dataset_root_path)\n",
    "    # shutil.rmtree(dataset_textgrid_path)\n",
    "    # shutil.rmtree(tar_file_path)\n",
    "\n",
    "    break\n",
    "\n",
    "# ffmpeg -y -loglevel error -i /home/knoriy/split_peoples_speech/pps_train/CC20160404BudgetFinance2of2/CC-2016-0404-BudgetFinance_2of2_DOT_mp3_00000.flac /home/knoriy/split_peoples_speech/pps_train/CC20160404BudgetFinance2of2/CC-2016-0404-BudgetFinance_2of2_DOT_mp3_00000.wav\n",
    "# mfa align --clean /home/knoriy/split_peoples_speech/pps_train/CC20160404BudgetFinance2of2/ english_mfa english_mfa /home/knoriy/split_peoples_speech/pps_train_textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "nohup sh -c \"wget https://the-peoples-speech-west-europe.bj.bcebos.com/part-00000-07a8f0d3-6d27-4299-887a-dc12a6d72f8d-c000.tar?authorization=bce-auth-v1/0ef6765c1e494918bc0d4c3ca3e5c6d1/2021-12-03T06%3A30%3A22Z/-1/host/444b9c082ceffd10f38bb965679ed9ec12202836831e111dd193fde281062d26 -O - | aws s3 cp - s3://s-laion/peoples_speech/train_clean_pps.tar\" &;\n",
    "nohup sh -c \"wget https://the-peoples-speech-west-europe.bj.bcebos.com/part-00000-4e132642-c01c-4db6-9db0-a1e19193f6f8-c000.json?authorization=bce-auth-v1/0ef6765c1e494918bc0d4c3ca3e5c6d1/2021-12-03T06%3A31%3A22Z/-1/host/d7dacf3c31d2e3670d82727636ce234be27a9128df7a80883b84b4a3d8c7f6c0 -O - | aws s3 cp - s3://s-laion/peoples_speech/Manifest.json\" &;\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22598391661e11fb86220d8e605c241deaf9a8263a5dee63ccb3c05da51e658c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aligner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e21918bae0143b5a633fbf1b4c6b5406aaf2f0d47fb4c4c8eb32f4c836e66610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
