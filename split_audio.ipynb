{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import textgrids\n",
    "import pandas as pd\n",
    "\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import shutil\n",
    "import fsspec\n",
    "from utils import generate_txt, get_subset_df, genorate_pps_df, make_tarfile, create_json_list\n",
    "\n",
    "chunk = 10\n",
    "generate_subset_tsv = True\n",
    "pps_df_dir = '/home/knoriy/split_peoples_speech/pps_train.tsv'\n",
    "\n",
    "root_path = '/home/knoriy/split_peoples_speech/'\n",
    "dataset_name = 'test'\n",
    "\n",
    "metadata_dir = \"/mnt/knoriy/metadata.json\"\n",
    "tar_dir = \"/mnt/knoriy/pps_train.tar\"\n",
    "\n",
    "# init Dirs\n",
    "dataset_root_path = os.path.join(root_path, f'{dataset_name}')\n",
    "dataset_textgrid_path = os.path.join(root_path, f'{dataset_name}_textgrids')\n",
    "dataset_split_path = os.path.join(root_path, f'{dataset_name}_split')\n",
    "s3 = fsspec.filesystem('s3')\n",
    "s3_dest = f's-laion/peoples_speech/{dataset_name}_tars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(pps_df_dir):\n",
    "    pps_df = pd.read_csv(pps_df_dir, sep='\\t', header=None, names=['audio_filepath', 'text'])\n",
    "else:\n",
    "    pps_df = genorate_pps_df(metadata_dir)\n",
    "    pps_df.to_csv(pps_df_dir, sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>is there anything to wear it on this one or ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>i thought the law was that we don't have juris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>review it yes you do yes you do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>this you know what happened there was a single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...</td>\n",
       "      <td>motion to abandon the quantity because nothing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320997</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00011.flac</td>\n",
       "      <td>reward of all our marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320998</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00012.flac</td>\n",
       "      <td>so i traveled back the way i'd come on it this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320999</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00013.flac</td>\n",
       "      <td>you state your business mister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321000</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00014.flac</td>\n",
       "      <td>come out yet i don't want to be just that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321001</th>\n",
       "      <td>The_Capture_movie/Capture_DOT_mp3_00015.flac</td>\n",
       "      <td>we're going to hire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4321002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            audio_filepath  \\\n",
       "0        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "1        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "2        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "3        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "4        gov_DOT_uscourts_DOT_ca9_DOT_04-56618/gov_DOT_...   \n",
       "...                                                    ...   \n",
       "4320997       The_Capture_movie/Capture_DOT_mp3_00011.flac   \n",
       "4320998       The_Capture_movie/Capture_DOT_mp3_00012.flac   \n",
       "4320999       The_Capture_movie/Capture_DOT_mp3_00013.flac   \n",
       "4321000       The_Capture_movie/Capture_DOT_mp3_00014.flac   \n",
       "4321001       The_Capture_movie/Capture_DOT_mp3_00015.flac   \n",
       "\n",
       "                                                      text  \n",
       "0        is there anything to wear it on this one or ha...  \n",
       "1        i thought the law was that we don't have juris...  \n",
       "2                          review it yes you do yes you do  \n",
       "3        this you know what happened there was a single...  \n",
       "4        motion to abandon the quantity because nothing...  \n",
       "...                                                    ...  \n",
       "4320997                         reward of all our marriage  \n",
       "4320998  so i traveled back the way i'd come on it this...  \n",
       "4320999                     you state your business mister  \n",
       "4321000          come out yet i don't want to be just that  \n",
       "4321001                                we're going to hire  \n",
       "\n",
       "[4321002 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file: This may take some time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_file_obj = tarfile.open(tar_dir, mode='r')\n",
    "print('opening file: This may take some time\\n')\n",
    "\n",
    "file_names_full_list = src_file_obj.getnames()\n",
    "file_names_full_list = [i for i in file_names_full_list if '.flac' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Files: 100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n",
      "Generating .txt files for MFA: 100%|██████████| 10/10 [00:00<00:00, 59.13it/s]\n",
      "Converting .flac files to .wav: 100%|██████████| 10/10 [00:02<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Setting up corpus information...\n",
      "INFO - Loading corpus from source files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.78it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Found 1 speaker across 10 files, average number of utterances per speaker: 10.0\n",
      "INFO - Initializing multiprocessing jobs...\n",
      "WARNING - Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs.\n",
      "INFO - Creating corpus split for feature generation...\n",
      "INFO - Generating base features (mfcc)...\n",
      "INFO - Generating MFCCs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.02it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Calculating CMVN...\n",
      "INFO - Creating corpus split with features...\n",
      "INFO - Compiling training graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.38it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Performing first-pass alignment...\n",
      "INFO - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Calculating fMLLR for speaker adaptation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Performing second-pass alignment...\n",
      "INFO - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Exporting TextGrids to /home/knoriy/split_peoples_speech/test_textgrids...\n",
      "INFO - Collecting phone and word alignments from alignment lattices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Finished exporting TextGrids to /home/knoriy/split_peoples_speech/test_textgrids!\n",
      "INFO - Done! Everything took 35.56912159919739 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spliting flac files into 5-10 seconds: 100%|██████████| 10/10 [00:01<00:00,  6.50it/s]\n",
      "Chunks remaining:   0%|          | 0/432101 [00:49<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(0, len(file_names_full_list), chunk), desc='Chunks remaining: '):\n",
    "    for file_name in tqdm.tqdm(file_names_full_list[i:i + chunk], desc=\"Extracting Files: \"):\n",
    "        src_file_obj.extract(file_name, f'./{dataset_name}/')\n",
    "\n",
    "    if generate_subset_tsv == True:\n",
    "        df = get_subset_df(f'{dataset_root_path}/**/*.flac', pps_df)\n",
    "\n",
    "    # Save transcript to file\n",
    "    save_all_text_to_file(df, dataset_name)\n",
    "\n",
    "    # Convert Flac to wav\n",
    "    convert_all_to_wav(df, os.path.join(root_path, dataset_name))\n",
    "\n",
    "    # Get audio text alignments and split audio\n",
    "    generate_textgrids(os.path.join(root_path, dataset_name))\n",
    "    split_all_audio_files(dataset_textgrid_path, dataset_root_path)\n",
    "\n",
    "\n",
    "    # # Upload Split files to s3\n",
    "    tar_file_path = make_tarfile(f'{dataset_split_path}', f'{dataset_root_path}/{i}.tar')\n",
    "    # s3.put(tar_file_path, os.path.join(s3_dest, os.path.basename(tar_file_path)))\n",
    "    # print('File Uploaded to: ', os.path.join(s3_dest, os.path.basename(tar_file_path)))\n",
    "    \n",
    "    # Upload sizes.jsonl to s3\n",
    "    create_json_list(json_sizes_path, {'filename':tar_file_path, 'num_samples':len(df)})\n",
    "    s3.put(json_sizes_path, 's-laion/peoples_speech/sizes.jsonl')\n",
    "    # shutil.rmtree(dataset_root_path)\n",
    "    # shutil.rmtree(dataset_textgrid_path)\n",
    "    # shutil.rmtree(dataset_split_path)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "nohup sh -c \"wget https://the-peoples-speech-west-europe.bj.bcebos.com/part-00000-07a8f0d3-6d27-4299-887a-dc12a6d72f8d-c000.tar?authorization=bce-auth-v1/0ef6765c1e494918bc0d4c3ca3e5c6d1/2021-12-03T06%3A30%3A22Z/-1/host/444b9c082ceffd10f38bb965679ed9ec12202836831e111dd193fde281062d26 -O - | aws s3 cp - s3://s-laion/peoples_speech/train_clean_pps.tar\" &;\n",
    "nohup sh -c \"wget https://the-peoples-speech-west-europe.bj.bcebos.com/part-00000-4e132642-c01c-4db6-9db0-a1e19193f6f8-c000.json?authorization=bce-auth-v1/0ef6765c1e494918bc0d4c3ca3e5c6d1/2021-12-03T06%3A31%3A22Z/-1/host/d7dacf3c31d2e3670d82727636ce234be27a9128df7a80883b84b4a3d8c7f6c0 -O - | aws s3 cp - s3://s-laion/peoples_speech/Manifest.json\" &;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = './sizes.json'\n",
    "\n",
    "entry = {'test':1}\n",
    "\n",
    "if not os.path.isfile(file_path):\n",
    "    a = []\n",
    "    a.append(entry)\n",
    "    with open(file_path, mode='w') as f:\n",
    "        f.write(json.dumps(a, indent=2))\n",
    "else:\n",
    "    with open(file_path, mode='r') as feedsjson:\n",
    "        feeds = json.load(feedsjson)\n",
    "        feeds.append(entry)\n",
    "    with open(file_path, mode='w') as f:\n",
    "        f.write(json.dumps(feeds, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22598391661e11fb86220d8e605c241deaf9a8263a5dee63ccb3c05da51e658c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aligner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e21918bae0143b5a633fbf1b4c6b5406aaf2f0d47fb4c4c8eb32f4c836e66610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
